<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zhouzhou🥣️</title>
  
  
  <link href="https://whoiskoala.github.io/atom.xml" rel="self"/>
  
  <link href="https://whoiskoala.github.io/"/>
  <updated>2022-08-10T23:09:17.583Z</updated>
  <id>https://whoiskoala.github.io/</id>
  
  <author>
    <name>Zhuhao Zhou</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>colab_1</title>
    <link href="https://whoiskoala.github.io/2022/08/10/colab-1/"/>
    <id>https://whoiskoala.github.io/2022/08/10/colab-1/</id>
    <published>2022-08-10T21:53:19.000Z</published>
    <updated>2022-08-10T23:09:17.583Z</updated>
    
    <content type="html"><![CDATA[<h1 id="colab-更改python版本和cuda版本">colab 更改python版本和cuda版本</h1><hr><p>运行github的开源代码的过程中发现要求使用的是3.6版本的python， 而colab自带的python版本是3.7，下文是将colab python版本修改为3.6的方法。</p><h2 id="问题描述">问题描述</h2><hr><p>colab 自带的python是3.7， 需要更改为python 3.6</p><p>查看colab 自带python版本： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!python -V</span><br></pre></td></tr></table></figure> 显示： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python 3.7.13</span><br></pre></td></tr></table></figure></p><h2 id="解决步骤">解决步骤</h2><hr><ol type="1"><li>卸载pip，之后再将pip重装在python 3.6下 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!python -m pip uninstall pip</span><br></pre></td></tr></table></figure></li><li>卸载自带的python，并下载python 3.6， 并设置使用python3.6 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!sudo update-alternatives --remove python /usr/local/bin/python</span><br><span class="line">!sudo apt install python3.6</span><br><span class="line">!update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.6 10</span><br></pre></td></tr></table></figure> 3.将pip重装在python3.6下，并查看python版本 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">!wget https://bootstrap.pypa.io/pip/3.6/get-pip.py</span><br><span class="line">!python get-pip.py</span><br><span class="line">!python -V</span><br></pre></td></tr></table></figure> 输出： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python 3.6.9</span><br></pre></td></tr></table></figure> ## 附加：修改cuda版本 为cuda 9.0 ******************************** <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">!wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb</span><br><span class="line">!dpkg -i cuda-repo-ubuntu1604-9-0-local_9.0.176-1_amd64-deb</span><br><span class="line">!apt-key add /var/cuda-repo-9-0-local/7fa2af80.pub</span><br><span class="line">!apt-get update</span><br><span class="line">!apt-get install cuda=9.0.176-1</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    
    <summary type="html">colab 修改python版本</summary>
    
    
    
    <category term="问题解决记录" scheme="https://whoiskoala.github.io/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="colab" scheme="https://whoiskoala.github.io/tags/colab/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu nvidia-drive 修复记录</title>
    <link href="https://whoiskoala.github.io/2022/08/04/n/"/>
    <id>https://whoiskoala.github.io/2022/08/04/n/</id>
    <published>2022-08-04T13:43:58.000Z</published>
    <updated>2022-08-04T14:33:47.149Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ubuntu-重启后执行nvidia-smi找不到驱动">Ubuntu 重启后执行nvidia-smi找不到驱动</h1><hr><p>之前遇到这种问题会直接重装nvidia驱动，非常的麻烦，这次的方用了三行命令解决了问题。 使用的修复方法来自 fihxc 文章链接:<a href="https://blog.csdn.net/fihxc/article/details/115583294" class="uri">https://blog.csdn.net/fihxc/article/details/115583294</a></p><h3 id="问题描述">问题描述</h3><p>重启Ubuntu之后在terminal里运行nvidia-smi 获得报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">NVIDIA-SMI has failed because it couldn’t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running</span><br></pre></td></tr></table></figure><h3 id="问题原因">问题原因</h3><p>ubantu的内核更新，但是更新后的ubantu内核导向的是最新的显卡驱动，内核的指向改变导致找不到之前安装的显卡驱动。</p><h3 id="解决步骤">解决步骤</h3><ol type="1"><li>安装DKMS： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install dkms</span><br></pre></td></tr></table></figure></li><li>查看之前驱动版本： <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /usr/src</span><br></pre></td></tr></table></figure> 显示： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">linux-headers-5.11.0-46-generic  linux-headers-5.4.0-59-generic    linux-hwe-5.15-headers-5.15.0-43</span><br><span class="line">linux-headers-5.13.0-52-generic  linux-headers-5.8.0-63-generic    linux-hwe-5.8-headers-5.8.0-63</span><br><span class="line">linux-headers-5.15.0-41-generic  linux-hwe-5.11-headers-5.11.0-46  nvidia-515.57</span><br><span class="line">linux-headers-5.15.0-43-generic  linux-hwe-5.13-headers-5.13.0-52</span><br><span class="line">linux-headers-5.4.0-59           linux-hwe-5.15-headers-5.15.0-41</span><br></pre></td></tr></table></figure></li><li>生成导向模块 <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dkms install -m nvidia -v 515.57</span><br></pre></td></tr></table></figure></li></ol><p>再次执行nvidia-smi， 成功显示显卡信息！</p>]]></content>
    
    
    <summary type="html">DKMS快速修复消失的nvidia驱动</summary>
    
    
    
    <category term="问题解决记录" scheme="https://whoiskoala.github.io/categories/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="NVIDIA-drive" scheme="https://whoiskoala.github.io/tags/NVIDIA-drive/"/>
    
  </entry>
  
  <entry>
    <title>Differentiable Scene Graphs 论文笔记</title>
    <link href="https://whoiskoala.github.io/2022/07/15/DSG-note/"/>
    <id>https://whoiskoala.github.io/2022/07/15/DSG-note/</id>
    <published>2022-07-15T09:39:39.000Z</published>
    <updated>2022-08-08T00:47:13.364Z</updated>
    
    <content type="html"><![CDATA[<h3 id="可微场景图原论文连接-httpsarxiv.orgabs1902.10200">可微场景图原论文连接 <a href="https://arxiv.org/abs/1902.10200" class="uri">https://arxiv.org/abs/1902.10200</a></h3><h2 id="abstract">abstract</h2><hr><p>复杂视觉场景的推理涉及对实体及其关系的感知。场景图(SGs)通过给实体(node)和关系(edge)分配标签，为推理任务提供了一种自然的表示。基于SGs的推理系统的训练通常分为两个步骤:首先，一个模型被训练来根据图像预测场景图，然后一个单独的模型被训练来根据预测的场景图进行推理。然而，以端到端方式训练这种系统似乎更可取。我们要解决的挑战是：场景图表示是不可微的，因此，还不知道怎么使用场景图作为中间组件。本论文提出可微场景图(DSGs)，一种可微端到端优化的图像表示，只需要从下游任务的监督。DSGs为所有区域和区域对提供密集表示，并且不花费建模能力在图像中不包含对象或相关关系的区域。我们评估了在三个基准数据集中识别参考关系（RR）的挑战性任务的模型：Visual Genome，VRD和CLEVR。将DSG作为中间表示会带来最前沿的表现。完整代码可在<a href="https://github.com/shikorab/dsg" class="uri">https://github.com/shikorab/dsg</a>上找到。</p><h2 id="introduction">introduction</h2><hr><p>理解丰富的视觉场景的完整语义是一项复杂的任务，包括检测单个实体，以及对实体的组合和它们之间的关系进行推理。为了共同表示实体和它们的关系，很自然地将它们视为一个图，其中节点是实体，边代表关系。这种表示通常被称为场景图(SGs)。由于SGs可以直接地对图像进行推理，因此已作出大量努力从原始图像中推断出它们。虽然场景图已被证明在各种任务中都是有用的，但将它们作为视觉推理系统的组成部分是具有挑战性的。(a)由于场景图是离散的表示，所以很难从下游任务中以端到端的方式学习它们。b)另一种方法是将SG预测器与监督数据分开进行预训练，但这需要费力且难以负担的人工注释。此外，预先训练的SG预测器有较差的收敛性，因为他们经过预先培训的标签很少适合下游任务的需求。例如，考虑到游行的图像和“指着骑在黑马上的军官”的问题，那匹马可能不是图中的节点，而“军官”一词可能不在词汇中。鉴于这些局限性，如何使场景图在视觉推理应用中发挥作用是一个有待解决的问题。在这项工作中，我们描述了可微场景图(DSG)，它解决了上述的挑战(图1)。</p><center><img data-src="figure1_iccv.jpg" width="50%"> <br><div style="color:orange;     display: inline-block;    color: #999;    padding: 2px;">图1.可微场景图:一种类似图的中间表示，为图像中的每个实体和实体对提供分布式表示。可微场景图可以用 梯度下降法以端到端的方式学习，只需要对下游的视觉推理任务进行监督(referring relationship)。</div></center><p>DSG是一种从下游推理任务的监督端到端训练的中间表示。其核心思想是放宽场景图的离散性，使每个实体和关系都用稠密可微的描述子来描述。我们展示了DSGs在解决参考关系(RR)任务中的好处(see Figure 1). 在这里，给定图像和triplet query&lt;subject，relation，object&gt;, 模型需要找到关系中subject和object的矩形框（bounding boxes）。我们用DSG作为中间组件训练RR模型。因此，DSG在训练时并没有对实体和关系进行直接监督，而是对下游RR任务使用多个监督信号。我们在三个标准RR数据集上评估了我们的方法:Vi-sual Genome、VRD和CLEVR，发现与最先进的方法相比，DSGs显著提高了性能。</p><p>综上所述，论文中的新贡献是:(1)一种新的可微分场景图表示方法，用于视觉推理，它能捕捉图像中多个实体及其关系的信息。我们描述了如何用一个下游的视觉推理任务来端到端训练DSG，而无需手动注释的场景图的直接监督。(2)以DSG为核心组件，提出了一种新的结构用于referring relationship任务。(3) Visual Genome、VRD和CLEVR数据集上referring relationship任务的最新研究结果。</p><h2 id="reffering-relationship-the-learning-setup">Reffering Relationship: The learning Setup</h2><hr><p>在引用关系任务中，我们得到一个图像<span class="math inline">\(I\)</span>和一个主题-关系-对象查询<span class="math inline">\(q=&lt;s,r,o&gt;\)</span>.目标是为主题输出一个边界框<span class="math inline">\(B_{s}\)</span>,为对象输出另一个边界框<span class="math inline">\(B_{o}\)</span>。在实践中，有时每一个都有几个边界框。图1给出了一个示例查询和预期输出。</p><p>根据“Referring Relationships” 论文，我们专注于用标注数据训练一个referring relationship。也就是说，我们使用一个由图像、查询和这些查询的正确方框组成的训练集。用$ {(I_{j}, q_{j}, (B_{j}^{S}, B_{j}^{o}))}_{j}^{N} $ 来表示。与[27]中一样，我们假设查询组件(主体、对象和关系)的词汇表是固定的。</p><p>在我们的模型中，我们把这个任务分成两个并行优化的部分。我们微调边框的位置，使它们紧密地覆盖实体，我们还将每个边框标记为以下四种可能的标签之一。标签Subject和Object对应于查询中的s和o实体。Other标签对应的是包含非查询主体或对象的实体(例如，人或任何其他类别，可以作为查询的主体或对象出现在查询中)的框。最后，标签Background对应于不包含实体的盒子。我们将上述两个模块称为Box Refiner和referentrelationships Classifier。</p><h2 id="differentiable-scene-graphs">Differentiable Scene Graphs</h2><hr><p>这一部分首先讨论了与标准场景图相比，使用可微场景图的中间表示的动机和潜在优势。然后，我们解释dsg如何适应我们的模型的整个体系结构。 ### Why use intermediate DSG layers?</p><p>一个完美的场景图(表示所有的实体和关系)捕捉了视觉推理所需的大部分信息，因此应该是有用的中间表示。这样的SG可以被下游的推理算法使用，使用预测的SG作为输入。不幸的是，学习预测任何下游任务的完美场景图是不可能的。首先，很少有足够的数据来训练好的SG预测者，其次，学习以一种独立于下游任务的方式来预测SGs，往往会产生不太相关的SGs。</p><p>相反，我们提出了一个中间表示，我们称之为可微场景图层(DSG)。DSG捕获场景图中的关系信息，但可以通过特定任务的方式进行端到端训练(图2)。与SGs一样，DSG保留视觉实体及其关系的描述符。与SGs不同的是，SGs的节点和边是用离散值(标签)标注的，DSG包含一个密集分布的表示向量，用于每个检测到的实体(称为节点描述符)和每对实体(称为边缘描述符)。这些表示本身就是输入图像的学习函数(详见补充)。与SGs一样，DSG只描述了涵盖利益实体及其关系的候选方框。与SGs不同，每个DSG描述符不仅捕获一个节点的本地信息，而且还捕获其上下文的信息。最重要的是，由于dsg是可微的，它们被用作下游视觉推理模块(在我们的例子中，一个引用环关系模块)的输入。</p><p>DSGs提供了几种计算和建模方面的优势：</p><p><strong>可微性。</strong> 由于节点描述子和边缘描述子是被检测框的可微函数，并被送入可微推理模块，因此可以使用梯度下降法对整个管道进行训练。</p><p><strong>密集的描述符。</strong> 通过保持节点和边的密集描述符，DSG保留了更多关于节点和边可能语义的信息，而不是过早地采用硬稀疏表示。这使得它能够更好地适应下游任务</p><p><strong>使用下游任务进行监督。</strong> 为训练场景图收集监督的标签是艰难而昂贵的。可以使用可用于下游任务的培训数据对DSGs进行训练，从而节省了昂贵的标签工作。另一方面，当标记的场景图可用于给定图像时，可以使用附加的损失组件在训练DSG时使用该数据。</p><p><strong>整体表示。</strong> DSG描述符是通过使用图神经网络从整个图像中集成全局信息来计算的（请参阅补充材料）。整个图像中的信息提高了对象和关系描述符的准确性。</p><center><img data-src="figure2.jpg" width="50%"> <br><div style="color:orange;     display: inline-block;    color: #999;    padding: 2px;"><p>图2。拟定的架构。输入由一个图像和一个关系查询组成，三元组主体、关系、对象。(1)检测器产生一组包围盒建议。(2) ROI-Align层使用方框从骨干网中提取对象特征。并行地，每一对方框建议用于计算联合方框，并以与对象特征相同的方式提取成对特征。(3)这些特征被用作可微分场景图生成模块的输入，该模块输出微分场景图，这是一组节点和边缘特征，由对输入特征应用图卷积网络产生。(4) DSG用于细化原始框建议，以及引用关系分类器，它将每个包围框建议分类为主题、对象、其他或背景。如果该建议出现在该图像的另一个查询关系中，则建议框的地面真实标签将为Other。否则地面真实标签将是Background。</p></div></center><h3 id="the-dsg-model-for-referring-relationships">The DSG Model for Referring relationships</h3><p>我们现在描述如何将dsg与其他模块结合起来解决视觉推理任务。模型的结构如图2所示。首先，模型提取图像中实体和关系的边界框。接下来，它在这些边界框上创建一个可微分的场景图。然后，两个输出模块使用DSG特性，目的是回答一个引用关系查询:一个Box Refiner模块对相关实体的边界框进行细化，一个参考关系分类器模块对每个框进行分类，分别为Subject、Object、Other或background.</p><p><strong>对象探测器.</strong> 我们使用standard region proposal network(RPN)来检测候选实体，并用<span class="math inline">\(b_{1}\)</span>，…，<span class="math inline">\(b_{B}\)</span> (<span class="math inline">\(B\)</span>可能因图像而异)。我们还为每个方框提取特征向量<span class="math inline">\(f_{i}\)</span>，并将其与方框坐标连接，得到<span class="math inline">\(zi = [f_{i};b_{i}]\)</span></p><p><strong>关系特征提取器。</strong> 给定任意两个边界盒<span class="math inline">\(b_{i}\)</span>和<span class="math inline">\(b_{j}\)</span>，我们考虑包含这两个盒(它们的并盒)的最小盒。我们用<span class="math inline">\(b_{i,j}\)</span>表示这个关系框，用<span class="math inline">\(f_{i,j}\)</span>表示它的特征。最后，我们用<span class="math inline">\(z_{i,j} = [f_{i,j};b_{i,j}]\)</span>表示特征<span class="math inline">\(f_{i,j}\)</span>和框坐标<span class="math inline">\(b_{i,j}\)</span>的拼接.</p><p><strong>可微的场景图生成器。</strong> 如上所述，DSG生成器的目标是将上述特征<span class="math inline">\(z_{i}\)</span>和<span class="math inline">\(z_{i,j}\)</span>转换为底层场景图的可微表示。即，将这些特征映射到一组新的密集向量<span class="math inline">\(z^{&#39;}_{i}\)</span>和<span class="math inline">\(z^{&#39;}_{i,j}\)</span>表示实体和关系。这种映射旨在结合每个特征向量的相关上下文。也就是说，表示zi包含关于第i个实体的信息，以及它的图像范围的上下文。有各种可能的方法来实现这种映射。这里我们使用[17]提出的模型，它使用图神经网络进行这种转换(参见补充材料)。 <strong>多任务目标</strong> 在许多领域，多任务目标训练可以提高单独任务的准确性，因为辅助任务作为正则化任务运行，推动内部表示远离过拟合，并向捕获输入的有用属性。我们在这里遵循这个想法并定义了一个多任务目标，它有三个组成部分:(a)引用关系分类器将方框匹配到主题和对象查询术语。(b) Box Refiner预测精确的紧密包围盒。(c)如果有相关的真实情况，包装盒标签识别包装盒中的视觉实体。 图3说明了前两个组件的效果，以及它们如何一起操作来细化边界框并将它们与查询条件匹配。具体来说，图3c显示了框细化如何产生围绕对象和主题紧密的框，图3d显示了RR分类如何匹配查询条件的框。</p>]]></content>
    
    
    <summary type="html">可微场景图论文阅读笔记</summary>
    
    
    
    <category term="论文笔记" scheme="https://whoiskoala.github.io/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="SGG" scheme="https://whoiskoala.github.io/tags/SGG/"/>
    
  </entry>
  
</feed>
